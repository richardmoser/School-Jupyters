{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Unsupervised Learning\n",
    "-  aim is to learn a mapping from the input space to an output space\n",
    "    - no pre-defined labels for the data\n",
    "        - i.e. just data, no \"correct\" answers to test against\n",
    "    - the model determines what features are important\n",
    "        - i.e. it is deciding how to group the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbde6cdebfe3fddd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-Means Clustering\n",
    "- split data into k clusters\n",
    "    - k is a hyperparameter\n",
    "    - first, find the centroid of a group of points and determine the distance of each point from the centroid\n",
    "    - then group the points by the closest centroid\n",
    "    - i.e. find the k centroids that minimize the distance between the grouped points and their respective centroids \n",
    "- variety of algorithms for moving centroids to new locations\n",
    "    - basic idea is to monitor the average distance of points from their centroids\n",
    "    - move around until the average distance is minimized and stops decreasing\n",
    "#### Reconstruction Error\n",
    "- used to determine the optimal number of clusters (k)\n",
    "- it is the sum of squared distances $x^t$ between each point and its centroid $m_i$\n",
    "    - Reconstruction Error $= \\sum_{t} \\sum_{i} ||x^t - m_i||^2$ \n",
    "- the best k is usually found at the \"elbow\" of the graph of the reconstruction error\n",
    "    - i.e. the point where the error stops decreasing as much\n",
    "    - <img src=\"images/recoerror.png\">\n",
    "#### Non-Deterministic\n",
    "- k-means clustering is non-deterministic\n",
    "    - i.e. it can give different results each time it is run\n",
    "- mitigation\n",
    "    - run the algorithm multiple times and choose the best result\n",
    "        - about 100 times usually works\n",
    "    - alternatively, use a uniform distribution of initial centroids\n",
    "        - this may miss a more optimal solution\n",
    "#### k-Means in Python\n",
    "- scikit-learn supports k-Means with `sklearn.cluster.Kmeans`\n",
    "    - `init` specifies the method for initializing the centroids\n",
    "        - `random` randomly selects k points from the data\n",
    "        - `k-means++` is a more sophisticated method\n",
    "    - `n_init` specifies the number of times to run the algorithm\n",
    "        - the best result is returned\n",
    "    - `inertia` is the reconstruction error\n",
    "#### Summary\n",
    "- advantages\n",
    "    - simple\n",
    "    - available in most libraries\n",
    "    - scales well\n",
    "    - applicable to many fields and problems\n",
    "- disadvantages\n",
    "    - requires k to be specified\n",
    "    - assumes that clusters are spherical in shape\n",
    "    - sensitive to outliers\n",
    "    - \"curse of dimensionality\"\n",
    "        - i.e. the more dimensions, the more data is needed to get good results\n",
    "        - PCA can help with this\n",
    "    - will always converge, but may be to a local minimum"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c97970646fa6ee4"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "24159bbe54424d99"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3cb00cfebb07d37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IC 26Oct23\n",
    "- 1. \n",
    "        - distance((1, 4, 8) -> (3, 8, 2))\n",
    "        - $d = \\sqrt{(1-3)^2 + (4-8)^2 + (8-2)^2}$\n",
    "        - $d = \\sqrt{4 + 16 + 36}$\n",
    "        - $d = \\sqrt{56}$\n",
    "        - $d = 7.483$\n",
    "- 2. \n",
    "        - centroid_1((2, 3, 4), (1, 6, 3), (2 ,1 ,5))\n",
    "        - $c_1 = (\\frac{2+1+2}{3}, \\frac{3+6+1}{3}, \\frac{4+3+5}{3})$\n",
    "        - $c_1 = (\\frac{5}{3}, \\frac{10}{3}, \\frac{12}{3})$\n",
    "        - $c_1 = (1.667, 3.333, 4)$\n",
    "        - centroid_2((6, 3, 5), (9, 8, 7), (7, 2, 6)) \n",
    "        - $c_2 = (\\frac{6+9+7}{3}, \\frac{3+8+2}{3}, \\frac{5+7+6}{3})$\n",
    "        - $c_2 = (\\frac{22}{3}, \\frac{13}{3}, \\frac{18}{3})$\n",
    "        - $c_2 = (7.333, 4.333, 6)$\n",
    "- 3.\n",
    "        - "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f23e6ea944bc1d7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Syllabification\n",
    "- common problem in applied linguistics\n",
    "- goal is to split a word into syllables\n",
    "    - i.e. \"syllabification\"\n",
    "- phones\n",
    "    - about 150 sounds which the human vocal tract can produce\n",
    "        - english uses about 44-62\n",
    "    - any word can be represented as a sequence of phones\n",
    "- sonority scale\n",
    "    - a ranking of speech phones by intensity from least to most sonorous\n",
    "        - here we will use a scale of 1-13\n",
    "        - i.e. how loud they are\n",
    "        - vowels are the most sonorous because they have the most vibration\n",
    "        - consonants are less sonorous because they have less vibration\n",
    "- sonority sequencing principle\n",
    "    - one of several theories on how words are split into syllables\n",
    "    - suggests that the middle of a syllable is the sonority apex (nucleus)\n",
    "        - usually a vowel\n",
    "    - can be applied to an audio file\n",
    "        - represent phones as a sequence of their intensities between 1 and 13\n",
    "        - how do you determine the exact place to separate the words based off of these numbers?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c96d003a0bf0bfef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Syllabification Problem Statement\n",
    "- need a set of rules to divide phones into syllables\n",
    "    - i.e. a syllabification algorithm\n",
    "    - rules are like look-up tables showing a pattern and the corresponding action\n",
    "        - e.g. if you have the pattern [13 12], split it into [13] & [12]\n",
    "        - e.g. if you have the pattern [13 5 10], split it into [13] & [5 10]\n",
    "- what if not in the table?\n",
    "    - find the closest matching pattern from the rules we do have\n",
    "        - uses euclidean distance\n",
    "        - <img src=\"images/syllabification.png\">"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a32dfc439e7e5db8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Syllable Alignment Error\n",
    "- the metric used to evaluate the accuracy of the syllabification algorithm\n",
    "    - an ugly, ugly function\n",
    "- compare the machine classified syllables to the human classified syllables\n",
    "    - calculate how much time each machine classified syllable overlaps with each human classified syllable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44751be86c29a061"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Syllabification Objective Function\n",
    "- $min_{e(r)} S(R,X)$\n",
    "    - $R$ is the set of rules\n",
    "    - r is a rule\n",
    "    - $e(r)$ is the error of a rule\n",
    "    - X is a set of utterances\n",
    "    - $S(R,X)$ is a function which takes R and X and returns a set of utterances broken into variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b7a62e39aefde7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Syllabification Genetic Algorithm\n",
    "- often use the TIMIT corpus to train the algorithm\n",
    "    - 6300 utterances\n",
    "    - 8 different dialects\n",
    "    - 630 different speakers\n",
    "    - speach is made up of\n",
    "        - dialect sentences to identify dialect\n",
    "        - phonetically rich sentences to identify common phonemes\n",
    "        - phonetically compact sentences to include interesting and problematic phoneme combinations \n",
    "    - also includes manually classified beginnings and endings of syllables and phones"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8864d883c054055"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IC 09Nov23\n",
    "- a. euclidean distance from [9 8 9] to [10 2 10] and [10 7 10]\n",
    "    - $d_1 = \\sqrt{(9-10)^2 + (8-2)^2 + (9-10)^2}$\n",
    "    - $d_1 = \\sqrt{1 + 36 + 1}$\n",
    "    - $d_1 = \\sqrt{38}$\n",
    "    - $d_1 \\approx 6.164$\n",
    "    - $d_2 = \\sqrt{(9-10)^2 + (8-7)^2 + (9-10)^2}$\n",
    "    - $d_2 = \\sqrt{1 + 1 + 1}$\n",
    "    - $d_2 = \\sqrt{3}$\n",
    "    - $d_2 \\approx 1.732$\n",
    "- b. [9] [8 9] "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c9a7f088a6e77ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Temporal Difference Learning\n",
    "- a form of reinforcement learning\n",
    "    - learning by trial and error\n",
    "    - i.e. learning by doing\n",
    "- Off-Policy\n",
    "    - trial and error\n",
    "- On-Policy\n",
    "    - learning from instruction\n",
    "    - follow the policy and learn about it at the same time\n",
    "- Q-Learning\n",
    "    - a form of off-policy learning\n",
    "    - uses a Q-table to store the value of each action in each state\n",
    "        - Q-table is initialized to 0\n",
    "        - Q-table is updated after each action\n",
    "        - Q-table is used to determine the next action\n",
    "    - e.g. robot in a house\n",
    "    <img src=\"images/qlearnstate.png\">\n",
    "\n",
    "    - use the state table to represent the options\n",
    "        - assign doors that lead outside a value of 100\n",
    "        - all other doors are assigned a value of 0\n",
    "    <img src=\"images/qlearnstaterewards.png\">\n",
    "\n",
    "    - create a rewards matrix and a Q matrix\n",
    "        - rewards matrix is the same as the state matrix\n",
    "        - Q matrix is initialized to 0 and is updated after each action\n",
    "        - Q matrix is like the brain or memory of the robot\n",
    "    - transition rule is dictated by Q(state, action) = R(state, action) + $\\gamma$ Max[Q(next state, all actions)]\n",
    "        - $\\gamma$ is the discount factor\n",
    "            - it is a value between 0 and 1\n",
    "            - it is used to determine how much to discount future rewards\n",
    "            - i.e. how much to discount the Max[Q(next state, all actions)]\n",
    "            - if $\\gamma$ is 0, then the robot will only consider the immediate reward\n",
    "            - if $\\gamma$ is 1, then the robot will consider all future rewards"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13b2f6b89fd36417"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q-Learning Algorithm\n",
    "- initialize Q-table to 0\n",
    "- for each episode\n",
    "    - select random initial state\n",
    "    - while state is not terminal\n",
    "        - randomly select an action\n",
    "        - consider taking this action\n",
    "        - get maximum Q-value for this state based on all possible actions\n",
    "        - compute Q(state, action)\n",
    "        - set the next state to the current state\n",
    "- e.g. initial state of 1 & $\\gamma$ = 0.8\n",
    "    <img src=\"images/qlearnroom1.png\">\n",
    "\n",
    "    - options are go to state 3 or state 5\n",
    "        - random selection\n",
    "    - choose 5\n",
    "    - calculate Q(1,5)\n",
    "        - R(1,5) = 100\n",
    "        - max[Q(next state, all actions)] = max[Q(5,1), Q(5,4), Q(5,5)] = Max[0, 0, 0] = 0\n",
    "        - Q(1,5) = 100 + 0.8 * 0 = 100\n",
    "    - append Q(1,5) to Q-table\n",
    "- e.g. initial state of 3 & $\\gamma$ = 0.8\n",
    "    - options are go to state 1, 2, or state 4\n",
    "        - random selection\n",
    "    - choose 1\n",
    "    - calculate Q(3,1)\n",
    "        - R(3,1) = 0\n",
    "        - max[Q(next state, all actions)] = max[Q(1,3), Q(1,5)] = Max[0, 100] = 100\n",
    "        - Q(3,1) = 0 + 0.8 * 100 = 80\n",
    "    - append Q(3,1) to Q-table\n",
    "- after many iterations, the Q-table will start to converge\n",
    "    <img src=\"images/qlearntable.png\">\n",
    "\n",
    "    - convergence can be defined as when the Q-table stops changing\n",
    "        - because the algorithm is exploratory, it may be worth continuing after the first identical iteration\n",
    "            - two iterations may not differ, but the third may differ significantly"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e06af629d59d243"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q-Learning vs Monte Carlo\n",
    "- Q-Learning can learn ***before*** knowing the final outcome\n",
    "    - can learn every step\n",
    "    - monte carlo can only learn at the end of the episode\n",
    "- Q-Learning can learn ***without*** the final outcome\n",
    "    - Q-Learning can learn from incomplete episodes\n",
    "    - monte carlo can only learn from complete episodes\n",
    "    - Q-Learning works in continuous (non-terminating) environments\n",
    "        - e.g. a robot in a house\n",
    "    - monte carlo only works in episodic (terminating) environments\n",
    "        - e.g. a robot in a maze"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd784c238e7c1d4f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "-\n",
    "<img src=\"images/ICP_28Nov.png\">"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b808575301fe07f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IC 28Nov23\n",
    "- initial state of 2 \n",
    "- options are go to state 3\n",
    "    - no random selection\n",
    "- calculate Q(2,3)\n",
    "    - R(2,3) = 0\n",
    "    - max[Q(next state, all actions)] = max[Q(3,1), Q(3,2), Q(3,4)] = Max[80, 0, 0] = 80\n",
    "    - Q(2,3) = 0 + 0.8 * 80 = 64\n",
    "- append Q(2,3) to Q-table\n",
    "- - - - - - - - \n",
    "- new state is 3\n",
    "- options are go to state 1 or state 2 or state 4\n",
    "    - random selection\n",
    "- go to state 1\n",
    "- calculate Q(3,1)\n",
    "    - R(3,1) = 0\n",
    "    - max[Q(next state, all actions)] = max[Q(1,3), Q(1,5)] = Max[0, 100] = 100\n",
    "    - Q(3,1) = 0 + 0.8 * 100 = 80\n",
    "- append Q(3,1) to Q-table\n",
    "- - - - - - - - \n",
    "- new state is 1\n",
    "- options are go to state 3 or state 5\n",
    "    - random selection\n",
    "- go to state 5\n",
    "- calculate Q(1,5)\n",
    "    - R(1,5) = 100\n",
    "    - max[Q(next state, all actions)] = max[Q(5,1), Q(5,4), Q(5,5)] = Max[0, 0, 0] = 0\n",
    "    - Q(1,5) = 100 + 0.8 * 0 = 100\n",
    "- append Q(1,5) to Q-table"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10ce045efc1e2445"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T23:05:06.198450200Z",
     "start_time": "2023-11-28T23:05:06.191452500Z"
    }
   },
   "id": "36ae12bd7c6e80f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fe220778ebb8abf4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
