{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T17:57:21.737538300Z",
     "start_time": "2023-10-03T17:57:21.729437Z"
    }
   },
   "id": "b17f776d527f22cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Threads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2abedc3e5270b49e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Motivation\n",
    "- issues with single process software\n",
    "    - only one thing can happen at a time\n",
    "    - if one thing takes a long time, everything else has to wait\n",
    "    - if one thing crashes, everything else crashes\n",
    "    - not great resource utilization\n",
    "        - e.g. other CPU cores are idle\n",
    "    -  creating a new process for every task is expensive\n",
    "        - e.g. memory, startup time, message passing, \n",
    "        - lots of processes means lots of context switching\n",
    "            - processes are good for isolation, but not for performance\n",
    "            - in interdependent tasks in a single program, isolation/protection is not needed\n",
    "- need a solution\n",
    "    - to run multiple sequences of code for different objects\n",
    "    - that shares data effectively\n",
    "    - that switches between sequences of code efficiently\n",
    "#### Threads\n",
    "- designed for the above\n",
    "- allow concurrent execution of a sequence of code\n",
    "- also known as a lightweight process\n",
    "    - instead of duplicating the entire process, only the minimal information needed to run the code is duplicated\n",
    "        - PC, registers, stack, state, misc\n",
    "        - processes also include data, heap, code regions\n",
    "    - executed within a process\n",
    "        - if any thread calls exit(), the entire process terminates\n",
    "            - all threads share the same address space will be terminated\n",
    "        - all threads share the same address space\n",
    "            - can access the same data\n",
    "                - no protection (but that shouldn't be needed)\n",
    "            - can communicate with each other easily\n",
    "    - smaller context\n",
    "        - i.e. less information to save and restore from PCB\n",
    "        - does not require duplicating the process's address space\n",
    "            - only the stack is duplicated\n",
    "        - slightly faster context switching\n",
    "    - single address space for all threads in a process\n",
    "    - shared data:\n",
    "        - process instructions\n",
    "        - most data\n",
    "        - open files\n",
    "        - signals and signal handlers\n",
    "        - current working directory\n",
    "        - user and group id\n",
    "    - thread specific data:\n",
    "        - thread id\n",
    "        - set of registers, stack pointer\n",
    "        - stack\n",
    "        - thread specific data\n",
    "        - signal mask\n",
    "            - thread can block signals\n",
    "        - scheduling properties\n",
    "            - e.g. priority\n",
    "        - return value\n",
    "- <img src=\"images/threads.png\" width=\"800px\">\n",
    "    - stack is partitioned for thread 1 and 2\n",
    "- benefits\n",
    "    - responsiveness\n",
    "        - user interface can remain responsive while performing long-running tasks\n",
    "        - if one thread is blocked, another thread can run\n",
    "    - resource sharing\n",
    "        - threads share resources of the process\n",
    "            - memory, files, etc.\n",
    "            - requires synchronization to avoid conflicts (e.g. two threads writing to the same file)\n",
    "        - easier than shared memory or message passing\n",
    "    - economy\n",
    "        - creating a new thread is cheaper than creating a new process\n",
    "            - less overhead\n",
    "            - faster\n",
    "            - less memory\n",
    "            - easier\n",
    "    - scalable\n",
    "        - can take advantage of multiprocessor architectures\n",
    "            - e.g. one thread per processor\n",
    "- primary drawback\n",
    "    - no inbuilt protection\n",
    "        - threads share the same address space\n",
    "        - one thread can easily corrupt another thread's stack\n",
    "        - one thread can easily overwrite another thread's data, code, etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bb7b5c85bf315a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linux Implementation\n",
    "- some flavors have different implementations or do not support threads\n",
    "- most Linux supports POSIX threads (pthreads)\n",
    "    - POSIX is a standard for portable operating systems\n",
    "    - Pthreads is a standard IEEE POSIX C library for threads\n",
    "    - can be either used at user-level or kernel level\n",
    "- Pthreads API\n",
    "    - thread management\n",
    "        - functions to create, destroy, join, detach thread attributes\n",
    "    - mutexes\n",
    "        - functions to enforce synchronization\n",
    "        - create, destroy, lock, unlock mutexes\n",
    "    - condition variables\n",
    "        - functions to manage thread communication\n",
    "        - create, destroy, wait, signal, broadcast signals\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "103ae6096426c446"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```C\n",
    "#include <pthread.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int sum; /* data shared by all threads */\n",
    "void *runner(void *param); /* thread function prototype */\n",
    "\n",
    "int main (int argc, char *argv[])\n",
    "{\n",
    "    pthread_t tid; /* thread identifier */\n",
    "    pthread_attr_t attr /* set of thread attributes */\n",
    "\n",
    "    if(atoi(argv[1]) < 0) { // atoi converts string to integer\n",
    "        fprintf(stderr, “%d must be >=0\\n”, atoi(argv[1]));\n",
    "        return -1;\n",
    "    }\n",
    "    /* get the default thread attributes */\n",
    "    pthread_attr_init(&attr);\n",
    "\n",
    "    /* create the thread */\n",
    "    pthread_create(&tid, &attr, runner, argv[1]); // pass tid and attr by reference, runner is the function to be executed, and argv[1] is the argument to the function runner\n",
    "\n",
    "    /* wait for the thread to exit */\n",
    "    pthread_join(tid, NULL);\n",
    "    fprintf(stdout, “sum = %d\\n”, sum);\n",
    "\n",
    "    /* The thread will begin control in this function */\n",
    "    void *runner (void  *param)\n",
    "    {\n",
    "        int i, upper = atoi(param);\n",
    "        sum = 0;\n",
    "        for(i=1 ; i<=upper ; i++)\n",
    "            sum += i;\n",
    "        pthread_exit(0);\n",
    "    }\n",
    "}\n",
    "```\n",
    "- `void *` functions are functions that return a pointer to void\n",
    "    - i.e. they be typecasted to any type\n",
    "- thread attributes cannot be changed after the thread is created\n",
    "- API Calls\n",
    "    - pthread_attr_init – initialize the thread attributes object\n",
    "        - int pthread_attr_init(pthread_attr_t *attr);\n",
    "        - defines the attributes of the thread created\n",
    "            - scope, detach state, stack size, stack addr, scheduling policy \n",
    "    - pthread_create – create a new thread\n",
    "        - int pthread_create(pthread_t *restrict thread, const pthread_attr_t *restrict attr,  \t\t\tvoid *(*start_routine)(void*), void *restrict arg);\n",
    "        - upon success, a new thread id is returned in thread\n",
    "    - pthread_join – wait for thread to exit\n",
    "        - int pthread_join(pthread_t thread, void **value_ptr);\n",
    "        - calling process blocks until thread exits\n",
    "    - pthread_exit – terminate the calling thread\n",
    "        - void pthread_exit(void *value_ptr);\n",
    "        - make return value available to the joining thread"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13a5452635452d11"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exam Information\n",
    "- wednesday, 04Oct23\n",
    "- review questions have been posted\n",
    "- similar format and questions to quizzes\n",
    "    - some open ended questions as well\n",
    "- in class review monday\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f992aa4c5a1f2d80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### User vs Kernel Threads\n",
    "- user level\n",
    "    - advantages\n",
    "        - efficient and flexible in space, speed, switching, and scheduling\n",
    "    - disadvantages\n",
    "        - one thread blocked on IO blocks all threads\n",
    "        - difficult to automatically take advantage of SMP (symmetric multiprocessing)\n",
    "- kernel level\n",
    "    - advantages\n",
    "        - removes disadvantages of user level threads\n",
    "    - disadvantages\n",
    "        - slower and more expensive\n",
    "        - less flexible\n",
    "        - more overhead\n",
    "        - less portable\n",
    "        - above are due to kernel involvement\n",
    "    - provided by most modern general purpose operating systems\n",
    "        - e.g. Linux, Windows, Solaris, etc.\n",
    "### Multithreading Models\n",
    "- many to one\n",
    "    - many user level threads mapped to one kernel thread \n",
    "    - <img src=\"images/mto1.png\" height=\"300px\">\n",
    "- one to one\n",
    "    - one user level thread mapped to one kernel thread\n",
    "    - <img src=\"images/1to1.png\" height=\"150px\">\n",
    "    - e.g. linux pthreads (used in the lab)\n",
    "- many to many\n",
    "    - many user level threads mapped to many kernel threads\n",
    "    - <img src=\"images/mtom.png\" height=\"300px\">\n",
    "- two level model\n",
    "    - similar to many to many but allows a user thread to be bound to a kernel thread\n",
    "    - <img src=\"images/2level.png\" height=\"300px\">"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75ec5c26d09b47bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Threading Issues\n",
    "- fork() and exec()\n",
    "    - fork() duplicates the entire process\n",
    "        - all threads are duplicated\n",
    "        - child process has the same number of threads as the parent\n",
    "        - some systems include two versions of fork()\n",
    "            - one that duplicates all threads\n",
    "            - one that duplicates only the calling thread\n",
    "        - linux only has one version of fork()\n",
    "            - duplicates only the thread that called fork()\n",
    "    - exec() replaces the process's memory space\n",
    "        - all threads are destroyed\n",
    "        - only the thread that called exec() remains\n",
    "        - linux\n",
    "            - complete replacement of the process's memory space\n",
    "                - i.e. all threads are overwritten\n",
    "    - solution\n",
    "        - call fork() then call exec() immediately after\n",
    "            - only the calling thread is duplicated\n",
    "- thread cancellation of target thread\n",
    "    - termination of a thread before it has finished\n",
    "    - asynchronous cancellation\n",
    "        - terminates the target thread immediately\n",
    "        - allocated resources are not freed\n",
    "        - status of shared data may be ill-defined\n",
    "    - deferred cancellation\n",
    "        - target thread terminates itself\n",
    "            - periodically checks if it should terminate\n",
    "        - orderly cancellation can be easilly achieved\n",
    "        - failure to check for cancellation requests may result in issues\n",
    "    - linux supports both\n",
    "        - pthread_cancel()\n",
    "            - see man page for details\n",
    "- signal handling\n",
    "    - signals notify a process that an event has occurred\n",
    "        - e.g. divide by zero, kill, etc.\n",
    "    - signal handlers process signals\n",
    "        - e.g. ignore, catch, etc.\n",
    "        - OS may deliver the signal to the appropriate process\n",
    "        - OS or process handles the signal\n",
    "    - signal types\n",
    "        - synchronous\n",
    "            - generated by the process\n",
    "            - something **in** your process caused the signal\n",
    "                - you can point to the line of code that caused the signal\n",
    "                - e.g. divide by zero, segmentation fault, etc.\n",
    "                    - segfault is caused by the assembly instructions load or store\n",
    "                    - if the address to be accessed is not valid, the OS sends a segfault signal\n",
    "        - asynchronous\n",
    "            - generated by the OS or another process\n",
    "            - something **outside** of your process caused the signal\n",
    "                - you cannot point to the line of code that caused the signal\n",
    "                - e.g. kill, ctrl-c, etc.\n",
    "    - delivery options\n",
    "        - deliver to the thread to which the signal applies\n",
    "            - e.g. divide by zero\n",
    "        - deliver to every thread in the process\n",
    "            - e.g. ctrl-c\n",
    "        - deliver to certain threads in the process\n",
    "        - assign a specific thread to receive all signals for the process\n",
    "- implicit threading\n",
    "    - correct multi-threaded programs\n",
    "        - can cause latency and performance issues\n",
    "        - is more difficult to write and debug\n",
    "    - compilers and runtime libraries aid in creating and managing threads\n",
    "        - semi-automatic parallelization\n",
    "            - compiler identifies loops that can be parallelized\n",
    "            - compiler generates code to create threads and manage them\n",
    "            - compiler generates code to synchronize threads\n",
    "    - some methods of implicit threading\n",
    "        - thread pools\n",
    "            - motivation\n",
    "                - creating a new thread is expensive\n",
    "                - overshooting the bound on concurrent threads is wasteful\n",
    "            - create a number of threads at startup where they wait for work\n",
    "            - number of threads is based on the number of processors\n",
    "            - advantages\n",
    "                - faster to service a request with an existing thread than to create a new one\n",
    "                - allows the number of threads to be bound to the number of processors\n",
    "        - OpenMP\n",
    "            - compiler directives for an API for C, C++, and Fortran\n",
    "            - supports parallel programming in shared memory environments\n",
    "            - user specifies parallel regions\n",
    "            - create as many threads as there are cores\n",
    "            - run for loop in parallel\n",
    "            - OpenMPI is like OpenMP but for distributed memory environments\n",
    "                - i.e. multiple computers won't have shared memory so you need to use message passing\n",
    "            - tl;dr\n",
    "                - user tells compiler when, where, and how to parallelize\n",
    "                - compiler handles most of the menial labor and detail work\n",
    "        - Grand Central Dispatch, MS Thread Building Blocks (TBB), java.util.concurrent package\n",
    "            - libraries that provide thread pools and other threading features\n",
    "        - "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e9791de54e92382"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### OpenMP example\n",
    "```C\n",
    "#include <omp.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        printf(\"In a parallel region\\n\");\n",
    "    }\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "- should print \"In a parallel region\" as many times as there are cores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a4df8481dd3ad7b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linux Threads\n",
    "- referred to them as tasks\n",
    "- relies on the `clone()` system call\n",
    "    - `clone()` can be used to create a new process or thread \n",
    "    - flags\n",
    "        - `CLONE_VM`\n",
    "            - allows a child process to share the address space of the parent\n",
    "        - `CLONE_FILES`\n",
    "            - allows a child process to share the set of open files with the parent\n",
    "        - `CLONE_FS`\n",
    "            - allows a child process to share the same file system as the parent\n",
    "        - `CLONE_SIGHAND`\n",
    "            - allows a child process to share the same signal handlers as the parent\n",
    "    - allows a child process to share the address space of the parent\n",
    "### Multicore Processors\n",
    "- <img src=\"images/microprocessortrends.png\">\n",
    "- multiple cores on a single chip\n",
    "- motivation\n",
    "    - power wall\n",
    "        - power consumption increases with frequency\n",
    "    - frequency scaling has hit a wall\n",
    "        - heat dissipation is the primary limiting factor\n",
    "            - heat generation is $\\propto$ frequency$^3$\n",
    "    - transistor density scaling\n",
    "        - transistor density increases with time\n",
    "        - transistor size decreases with time\n",
    "        - transistor speed increases with time\n",
    "        - transistor power consumption decreases with time\n",
    "        - transistor cost decreases with time\n",
    "- multicore vs multiprogramming programming\n",
    "    - same-chip communication is faster\n",
    "    - shared memory is faster and easier than message passing\n",
    "- multicore vs multiprocessor vs multicomputer\n",
    "    - multicore\n",
    "        - multiple cores on a single chip\n",
    "        - cores share the same memory\n",
    "        - cores share the same cache\n",
    "        - cores share the same bus\n",
    "        - cores communicate via shared memory\n",
    "    - multiprocessor\n",
    "        - multiple processors on a single chip\n",
    "        - processors have their own memory\n",
    "        - processors have their own cache\n",
    "        - processors share the same bus\n",
    "        - processors communicate via message passing\n",
    "    - multicomputer\n",
    "        - multiple computers\n",
    "        - computers have their own memory\n",
    "        - computers have their own cache\n",
    "        - computers have their own bus\n",
    "        - computers communicate via message passing\n",
    "- code must be written to utilize multiple cores\n",
    "    - e.g. OpenMP\n",
    "    - means that simply having more cores does not mean that your program will run faster\n",
    "    - one of the primary reasons that PCs don't have more cores\n",
    "        - most programs are not written to take advantage of more cores\n",
    "- challenges\n",
    "    - division of work\n",
    "        - how to divide the work among the cores\n",
    "        - how to assign work to cores\n",
    "    - data splitting\n",
    "        - how to divide the data among the cores\n",
    "    - data dependency\n",
    "        - how to handle dependencies between data and concurrent tasks\n",
    "    - testing and debugging\n",
    "        - how to test and debug concurrent programs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "304a737f81400c01"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
