{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T21:16:09.696852500Z",
     "start_time": "2023-08-29T21:16:08.450013800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ML Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Supervised Machine Learning\n",
    "- Training, Validation, Testing datasets\n",
    "    - Training: used to train the model\n",
    "    - Validation: used to tune the hyperparameters\n",
    "        - Hyperparameters: parameters that are not learned by the model\n",
    "        - modern models often handle this automatically\n",
    "        - terminology has evolved so older sources may say validation but mean testing data\n",
    "    - Testing: used to evaluate the model\n",
    "- Cross Validation\n",
    "    - iteratively train and test the model on different subsets of the data\n",
    "    - allows you to use all of the data for training and testing without overfitting (hopefully)\n",
    "    - Leave-One-Out Cross Validation (LOOCV)\n",
    "        - train on all but one data point\n",
    "        - test on the one data point\n",
    "        - repeat for all data points\n",
    "        - pros: uses all data for training and testing\n",
    "        - cons: computationally expensive and can lead to overfitting\n",
    "        - **Should not be used**\n",
    "    - k-fold Cross Validation\n",
    "        - split data into k subsets\n",
    "        - train on k-1 subsets\n",
    "        - test on the remaining subset\n",
    "        - repeat for all subsets\n",
    "        - pros: computationally efficient\n",
    "        - cons: uses less data for training and testing\n",
    "  ### We will use 2-fold cross validation for this course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### USeful Python Libraries\n",
    "- NumPy\n",
    "    - good for linear algebra\n",
    "- scikit-learn\n",
    "    - good for machine learning\n",
    "- pandas\n",
    "    - good for data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T21:16:12.827411100Z",
     "start_time": "2023-08-29T21:16:12.772411800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "url = \"files/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length',\n",
    "'petal-width', 'class']\n",
    "dataset = read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T21:16:13.605692400Z",
     "start_time": "2023-08-29T21:16:13.527110200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Most scikit-learn library functions use the following convention:\n",
    "- X is an array containing all the features in the first columns and the class in the last column.\n",
    "- y is an array containing only the classes.\n",
    "- Note: Test_size must be set to 0.50 for 2-fold cross-validation which we will be using in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T21:16:14.901553300Z",
     "start_time": "2023-08-29T21:16:14.852416800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create Arrays for Features and Classes\n",
    "array = dataset.values\n",
    "X = array[:,0:4] #contains flower features (petal length, etc..)\n",
    "y = array[:,4] #contains flower names\n",
    "#Split Data into 2 Folds for Training and Test\n",
    "X_Fold1, X_Fold2, y_Fold1, y_Fold2 = train_test_split(X, y, test_size=0.50, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T21:26:09.117912100Z",
     "start_time": "2023-08-24T21:26:08.477531200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GaussianNB() #create model of type Gaussian Naive Bayes\n",
    "model.fit(X_Fold1, y_Fold1)  #train model on Fold1\n",
    "pred1 = model.predict(X_Fold2)  #test model on Fold2\n",
    "model.fit(X_Fold2, y_Fold2)  #train model on Fold2\n",
    "pred2 = model.predict(X_Fold1)  #test model on Fold1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluating the Model\n",
    "- used to quantify\n",
    "    - desired performance vs actual performance\n",
    "    - desired vs baseline performance\n",
    "    - progress over time\n",
    "- Accuracy\n",
    "    - number of correct predictions / total number of predictions\n",
    "    - good for balanced datasets\n",
    "    - bad for unbalanced datasets\n",
    "- Confusion Matrix\n",
    "    - shows the number of correct and incorrect predictions\n",
    "    - good for unbalanced datasets\n",
    "    - at it's most basic, made up of 4 values\n",
    "        - true positives (TP)\n",
    "        - true negatives (TN)\n",
    "        - false positives (FP)\n",
    "        - false negatives (FN)\n",
    "        - FP and FN are often called Type I and Type II errors\n",
    "        - <img src=\"images/FP_and_FN.png\" alt=\"drawing\" width=\"500\"/>\n",
    "    - accuracy, precision, recall, and F1 score can be calculated from the confusion matrix\n",
    "        - accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "                - how often the model is correct\n",
    "        - precision = TP / (TP + FP)\n",
    "                - how often the model is correct when it predicts positive\n",
    "        - recall = TP / (TP + FN)\n",
    "                - how often the model predicts positive when it is correct\n",
    "        - F1 score = 2 * (precision * recall) / (precision + recall)\n",
    "                - harmonic mean of precision and recall\n",
    "                - good for unbalanced datasets\n",
    "    - F-Score\n",
    "        - F-Score or F-measure is used in statistical analysis of binary classification\n",
    "        - F-Score is the harmonic mean of precision and recall\n",
    "        - highest possible value is 1.0\n",
    "        - lowest possible value is 0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Multiclass Confusion Matrices\n",
    "- confusion matrices can be extended to multiclass problems\n",
    "    - e.g.\n",
    "        - <img src=\"images/multiclass.png\" alt=\"drawing\" width=\"500\"/>\n",
    "        - precisoin of cat is from the horizontal cat row, 4/13\n",
    "        - recall of cat is from the vertical cat column, 4/6\n",
    "- there is no standard orientation of the matrix\n",
    "    - i.e. the predicted and true labels can be on the rows or columns\n",
    "    - so always read the labels\n",
    "    - the diagonal is always the true positives\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T21:49:45.444852200Z",
     "start_time": "2023-08-24T21:49:45.416939700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Confusion Matrix:\n",
      "[[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        50\n",
      "  Versicolor       0.94      0.94      0.94        50\n",
      "   Virginica       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.96       150\n",
      "   macro avg       0.96      0.96      0.96       150\n",
      "weighted avg       0.96      0.96      0.96       150\n"
     ]
    }
   ],
   "source": [
    "actual = np.concatenate([y_Fold2, y_Fold1])  #combine the actual labels from both folds\n",
    "predicted = np.concatenate([pred1, pred2])   #combine the predicted labels from both folds\n",
    "print(f\"Accuracy: {accuracy_score(actual, predicted)}\")   #print the accuracy\n",
    "print(\"Confusion Matrix:\")   #print the confusion matrix\n",
    "print(confusion_matrix(actual, predicted))   #print the confusion matrix\n",
    "print(\"Classification Report:\")   #print the classification report\n",
    "print(classification_report(actual, predicted))   #print the classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Regression Classifiers\n",
    "- linear regression\n",
    "    - single input variable\n",
    "    - $y = b_0 + b_1x$\n",
    "        - $y$ is the response\n",
    "        - $b_0$ is the bias coefficient\n",
    "        - $b_1$ is the coefficient for the input variable\n",
    "    - training data is used to find the values of the coefficients\n",
    "        - finding the best fit line\n",
    "        - many different algorithms can be used to find the best fit line\n",
    "            - ordinary least squares\n",
    "            - gradient descent\n",
    "            - stochastic gradient descent\n",
    "            - etc...\n",
    "    - once the coefficients are found, the model can be used to make predictions\n",
    "        - $y = 0.5 + 0.8x$\n",
    "        - $y = 0.5 + 0.8(5)$\n",
    "        - $y = 4.5$ \n",
    "- polynomial regression\n",
    "    - nonlinear relationship between the input and response\n",
    "        - $y = b_0 + b_1x + b_2x^2 +$ ...    \n",
    "    - formulas are typically represented as matrices\n",
    "- multiple linear regression\n",
    "    - multiple input variables\n",
    "    - $y = b_0 + b_1x_1 + b_2x_2 +$ ...\n",
    "    - formulas are typically represented as matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T21:16:20.908975300Z",
     "start_time": "2023-08-29T21:16:20.828248200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "# print(x)\n",
    "# print(y)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression() #create model of type Linear Regression\n",
    "model.fit(x, y)  #train model on data\n",
    "# model = LinearRegression().fit(x, y) # oneliner for the above 2 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluating Regression Models\n",
    "- $R^2$ is a measure of the fit\n",
    "- can be obtained with `.score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T21:17:20.675714800Z",
     "start_time": "2023-08-29T21:17:20.604367300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_0: 5.52257927519819\n",
      "[B_1 B_2]: [0.44706965 0.25502548]\n"
     ]
    }
   ],
   "source": [
    "model.score(x, y)\n",
    "print('B_0:', model.intercept_)\n",
    "print('[B_1 B_2]:', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Regression\n",
    "- Strengths\n",
    "    - straightforward to understand and explain\n",
    "    - can be regularized to avoid overfitting\n",
    "    - easily updated with new data via gradient descent\n",
    "- Weaknesses\n",
    "    - assumes a linear relationship between the input and response\n",
    "        - performs poorly with nonlinear relationships\n",
    "    - not flexible enough to capture more complex relationships\n",
    "        - e.g. polynomial regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### In Class 29Aug23\n",
    "\n",
    "1. a) Polynomial regression, the data clearly does not follow a straight line\n",
    "1. b) Linear regression, the data follows a straight line\n",
    "2.  \n",
    "- $y = 0.2 + 0.1x_1 + 0.05x_2$\n",
    "- $x_1 = 5.1$\n",
    "- $x_2 = 1.8$\n",
    "- $y = 0.2 + 0.1(5.1) + 0.05(1.8)$\n",
    "- $y = 0.2 + 0.51 + 0.09$\n",
    "- $y = 0.8$\n",
    "- The model predicts Iris-setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### scikit-learn Algorithm for Regression\n",
    "- needed for assignment 2\n",
    "- doesn't work without other code (as of 29Aug23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T20:47:39.866534300Z",
     "start_time": "2023-08-31T20:47:39.836295800Z"
    }
   },
   "outputs": [],
   "source": [
    "def regModel(name, model):\n",
    "    #Fit and transform data sets according to the regression degree\n",
    "    poly_reg = None\n",
    "    if (name == \"Linear Regression\"):\n",
    "        poly_reg = PolynomialFeatures(degree=1)\n",
    "    elif(name == \"2 Degree Polynomial Regression\"):\n",
    "        poly_reg = PolynomialFeatures(degree=2)\n",
    "    elif(name == \"3 Degree Polynomial Regression\"):\n",
    "        poly_reg = PolynomialFeatures(degree=3)\n",
    "    #create 2 folds\n",
    "    X_Poly1 = poly_reg.fit_transform(X_Fold1)\n",
    "    X_Poly2 = poly_reg.fit_transform(X_Fold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-08-31T20:47:40.714732Z",
     "start_time": "2023-08-31T20:47:39.843736900Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mfit(X_Poly1, y_Fold1) \u001B[38;5;66;03m#first fold training\u001B[39;00m\n\u001B[0;32m      2\u001B[0m pred1 \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_Poly2)\u001B[38;5;241m.\u001B[39mround() \u001B[38;5;66;03m#first fold testing\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#regression may produce values < 1 or > 3.\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X_Poly1, y_Fold1) #first fold training\n",
    "pred1 = model.predict(X_Poly2).round() #first fold testing\n",
    "#regression may produce values < 1 or > 3.\n",
    "pred1 = np.where(pred1 >= 3.0, 2.0, pred1) #map all values > 3 to 2\n",
    "pred1 = np.where(pred1 <= -1.0, 0.0, pred1) #map all values < 0 to 0\n",
    "model.fit(X_Poly2, y_Fold2) #second fold training\n",
    "pred2 = model.predict(X_Poly1).round() #second fold testing\n",
    "pred2 = np.where(pred2 >= 3.0, 2.0, pred2)\n",
    "pred2 = np.where(pred2 <= -1.0, 0.0, pred2)\n",
    "actual = np.concatenate([y_Fold2, y_Fold1])\n",
    "predicted = np.concatenate([pred1, pred2])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayesian Classifiers\n",
    "- simplest ML classifier\n",
    "- gold standard for comparing other classifiers\n",
    "    - if a new classifier is not better than a naive bayesian classifier, it is not worth using \n",
    "- based on Bayes' Theorem of conditional probability\n",
    "    - $P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$\n",
    "    - $P(A|B)$ is the probability of A given B\n",
    "    - $P(B|A)$ is the probability of B given A\n",
    "    - $P(A)$ is the probability of A\n",
    "    - $P(B)$ is the probability of B\n",
    "- mean and variance are used to summarize the data\n",
    "    - mean  $\\mu$\n",
    "         - the average\n",
    "        - $\\mu = \\frac{1}{n}\\sum_{i=1}^{n}x_i $\n",
    "    - variance $\\sigma^2$\n",
    "        - how much the data varies from the mean\n",
    "        - $\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\mu)^2 $\n",
    "- NB Classifiers are conditional probability models\n",
    "    - a sample to be classified is represented as a vector of features\n",
    "        - $x = (x_1, x_2, x_3, ..., x_n)$\n",
    "    - calculates the conditional probability of each class given the features\n",
    "        - $P(C_k|x_1, x_2, x_3, ..., x_n)$\n",
    "    - the class with the highest probability is the predicted class\n",
    "- problem\n",
    "    - if the number of features is large, classification by conditional probability is infeasible\n",
    "    - thus the model is reformulated to be more tractable\n",
    "        - the denominator is removed because it is effectively a constant\n",
    "- reduced form\n",
    "    - posterior numerator\n",
    "        - posterior numerator = prior * likelihood\n",
    "        - can estimate $p(x_k|C_i)$ from the training data\n",
    "            - $p(x_k|C_i) = \\frac{1}{\\sqrt{2\\pi\\sigma_{ik}^2}}e^{-\\frac{(x_k - \\mu_{ik})^2}{2\\sigma_{ik}^2}}$\n",
    "            - $x_k$ is the value of feature k in the sample\n",
    "            - $\\mu_{ik}$ is the mean of feature k for the entire training set\n",
    "            - $\\sigma_{ik}^2$ is the variance of feature k for the entire training set\n",
    "            - $C_i$ is the class\n",
    "            - $e$ is Euler's number (2.71828...)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Summary of Naive Bayes\n",
    "- Strengths\n",
    "    - simple and easy to implement\n",
    "    - fast\n",
    "    - good for high dimensional data\n",
    "    - good for categorical data\n",
    "    - good for text classification\n",
    "- Weaknesses\n",
    "    - assumes independence of features\n",
    "    - assumes a gaussian distribution of features\n",
    "    - based on probability theory\n",
    "        - real world data is often more complex\n",
    "    - can be outperformed by other classifiers\n",
    "- Training\n",
    "    - calculate one probability for each class\n",
    "    - calculate n * m conditional probabilities\n",
    "        - n is the number of class\n",
    "        - m is the number of features "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In Class 31Aug23"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T21:27:13.126359400Z",
     "start_time": "2023-08-31T21:27:13.104488500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
