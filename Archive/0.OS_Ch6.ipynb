{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04f7cbf385130b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T16:37:18.803296500Z",
     "start_time": "2023-11-03T16:37:18.735894200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fa7ddc89b880ec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Chapter 6: CPU Scheduling\n",
    "- multiprogramming\n",
    "    - goal: maximize CPU utilization\n",
    "    - most processes will alternate between CPU bursts and IO bursts\n",
    "        - CPU burst: process is running on the CPU\n",
    "        - IO burst: process is waiting for IO to complete\n",
    "    - schedule other processes while one is waiting for something\n",
    "- CPU bound process\n",
    "    - bounded by the CPU speed\n",
    "    - spends most of it's time in the CPU\n",
    "    - at least a few long CPU bursts\n",
    "- I/O bound process\n",
    "    - bounded by I/O speed\n",
    "    - spends most of it's time doing I/O\n",
    "    - many short CPU bursts\n",
    "### CPU Scheduler\n",
    "- selects from among the processes in memory that are ready to execute\n",
    "    - part of the OS dispatcher\n",
    "    - based on a particular scheduling algorithm\n",
    "- occurs when\n",
    "  1. process switches from running to waiting state\n",
    "  2. process switches from running to ready state\n",
    "  3. process switches from waiting/new to ready\n",
    "  4. process terminates\n",
    "- preemptive vs non-preemptive\n",
    "    - preemptive: scheduler can interrupt a process\n",
    "    - non-preemptive\n",
    "        - process gives up the CPU voluntarily\n",
    "        - easy, requires no special hardware\n",
    "        - poor response time for interactive and real-time systems\n",
    "    - preemptive\n",
    "        - OS can force a process to give up the CPU\n",
    "            - when process exceeds time slot\n",
    "            - when a higher priority process becomes ready\n",
    "        - requires special hardware (timer)\n",
    "        - may require synchronization \n",
    "        - favored by most OSes\n",
    "    - scheduling is non-preemptive under 1 and 4\n",
    "        - the process voluntarily gives up the CPU \n",
    "    - scheduling is preemptive under all other conditions\n",
    "        - the process is forced to give up the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa26f329481586b3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Dispatcher\n",
    "- functions\n",
    "    - get the new process from scheduler\n",
    "    - switch out the context of the current process\n",
    "    - give control of the CPU to the new process\n",
    "    - jump to the proper location in the new process\n",
    "- dispatch latency\n",
    "    - time taken by the dispatcher to stop one process and start another\n",
    "### Scheduling Queues\n",
    "- job queue\n",
    "    - set of all processes in the system\n",
    "    - scheduled by the long-term scheduler\n",
    "        - some OSes may not have a long-term scheduler\n",
    "            - e.g. phones, embedded systems, etc\n",
    "- ready queue\n",
    "    - set of all processes residing in main memory, ready and waiting to execute\n",
    "    - scheduled by the short-term or CPU scheduler\n",
    "- device queue\n",
    "    - set of processes waiting for an I/O device\n",
    "    - scheduled by the I/O scheduler\n",
    "    - I/O completion moves the process to the ready queue\n",
    "    - multiple processes can be waiting for the same device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20960927928c325",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Scheduling\n",
    "### Performance Metrics\n",
    "- CPU utilization\n",
    "    - keep the CPU as busy as possible\n",
    "        - i.e. keep the CPU utilization as close to 100% as possible\n",
    "    - 0% to 100%\n",
    "- Throughput\n",
    "    - number of processes that complete their execution per time unit\n",
    "- Turnaround time\n",
    "    - amount of time to execute a particular process\n",
    "    - time from submission to completion\n",
    "- Waiting time\n",
    "    - amount of time a process has been waiting in the ready queue\n",
    "- Response time\n",
    "    - amount of time it takes from when a request was submitted until the first response is produced\n",
    "    - for time-sharing systems\n",
    "    - may not be the same as turnaround time\n",
    "- Scheduling goals\n",
    "    - maximize CPU utilization\n",
    "    - minimize turnaround, wait, and response times\n",
    "    - fairness to processes and users\n",
    "        - starvation: a process may never be scheduled\n",
    "        - aging: increase priority of processes that have been waiting for a long time\n",
    "        - priority: some processes are more important than others\n",
    "        - interactive response time: users expect a quick response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2019954c3633afc0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluation Methods\n",
    "- Criteria\n",
    "    - specify relative importance of metrics\n",
    "    - consider system specific goals and measures\n",
    "- Deterministic modeling\n",
    "    - takes a particular predetermined workload and defines the performance of each algorithm for that workload\n",
    "        - i.e. a test workload simulation\n",
    "            - each algorithm is run on the same workload and the results are compared\n",
    "            - the workload is usually a set of processes with known CPU and IO bursts\n",
    "            - the results are usually the average of several runs\n",
    "    - simple and fast\n",
    "        - gives exact numbers\n",
    "    - difficult to generalize\n",
    "    - can recognize patterns over several inputs\n",
    "    - used for explaining and predicting behavior of algorithms\n",
    "### Workload Models and Grantt Charts\n",
    "- workload model\n",
    "    - set of processes that are submitted to the system\n",
    "    - may be real or synthetic\n",
    "    - <img src=\"images/workloadmodel.png\">\n",
    "        \n",
    "        - the burst times are the CPU bursts of the processes\n",
    "        - it is not the actual CPU burst times of the processes\n",
    "            - it is the burst time which the process would like to have\n",
    "- Grantt chart\n",
    "    - bar chart ilustrating a schedule\n",
    "    - <img src=\"images/granttchart.png\">\n",
    "        \n",
    "        - this figure shows a batch schedule \n",
    "            - i.e. a FCFS schedule\n",
    "            - ordered from P1 to P4 because they are submitted in that order\n",
    "    - chart will be different for different scheduling algorithms and different workloads\n",
    "- interpreting a Grantt chart\n",
    "    - <img src=\"images/granttinterp.png\">\n",
    "        \n",
    "        - A, B, and C are processes submitted at $t_0$\n",
    "        - turnaround time is the time from submission to completion\n",
    "            - $t_f - t_0$\n",
    "        - waiting time is the time spent in the ready queue\n",
    "            - e.g. for A it is the sum of the lengths of other processes before it's final burst\n",
    "                - i.e. B & C + B & C +nC\n",
    "        - response time is the time from submission to first response\n",
    "            - e.g. for A it is 0 because it starts executing immediately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f7e35f33e107e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Scheduling Algorithms\n",
    "- First Come First Serve\n",
    "    - schedules processes in the order they arrive in the ready queue\n",
    "    - non-preemptive\n",
    "    - implemented by FIFO queue\n",
    "    - advantages\n",
    "        - simple and easy to understand\n",
    "        - cannot cause starvation\n",
    "        - good for batch systems\n",
    "    - disadvantages\n",
    "        - average waiting time may be too long\n",
    "            - large variation based on arrival time\n",
    "        - cannot balance CPU and IO bound processes\n",
    "            - convoy effect - short process behind a long process\n",
    "        - not good for interactive systems or time-sharing systems\n",
    "    - e.g. P1, P2, P3\n",
    "        - <img src=\"images/FCFSeg.png\">\n",
    "        - <img src=\"images/FCFSeg1.png\">\n",
    "        - wait time (Pn) = completion - burst - arrival \n",
    "        - turnaround time (Pn) = completion - arrival \n",
    "        - wait time (P1) = 24 - 24 - 0 = 0\n",
    "        - turnaround time (P1) = 24 - 0 = 24\n",
    "        - wait time (P2) = 27 - 3 - 0 = 24\n",
    "        - turnaround time (P2) = 30 - 3 = 27\n",
    "        - average wait time = $\\frac{0 + 24 + 27}{3} = 17$\n",
    "    - e.g. P2, P3, P1\n",
    "        - <img src=\"images/FCFSeg2.png\">\n",
    "        - when the arrival same processes but different arrival order\n",
    "            - changes average wait time and turnaround time\n",
    "- Shortest Job First \n",
    "    - orders processes by shortest CPU burst\n",
    "    - allocates CPU to the process at the front of the list\n",
    "        - i.e. the process with the shortest CPU burst\n",
    "    - Advantage\n",
    "        - minimizes average waiting time\n",
    "        - guarantees that the average waiting time is optimal\n",
    "    - disadvantage\n",
    "        - requires knowledge of the length of the next CPU burst\n",
    "            - not possible in most cases\n",
    "            - how do you know the length of the next CPU burst for a process?\n",
    "        - can cause starvation\n",
    "            - long processes may never be scheduled\n",
    "    - e.g.\n",
    "      <img src=\"images/SJFeg.png\">\n",
    "            - wait time (P1) = 9 - 6 = 3\n",
    "            - wait time (P2) = 24 - 8 = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc148df9e13a23",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Estimating Length of Next CPU Burst\n",
    "- can only be estimated\n",
    "    - many models for prediction\n",
    "- we will use an exponential average of past burst length\n",
    "- Formula\n",
    "    1. $t_n$ = actual length of the nth CPU burst\n",
    "    2. $\\tau_{n+1}$ = predicted value for the next CPU burst\n",
    "    3. $\\alpha, 0 \\leq \\alpha \\leq 1$ \n",
    "    4. $\\tau_{n+1} = \\alpha t_n + (1 - \\alpha) \\tau_n$\n",
    "    - if $\\alpha = 0$ then $\\tau_{n+1} = \\tau_n$\n",
    "        - recent history does not matter\n",
    "    - if $\\alpha = 1$ then $\\tau_{n+1} = t_n$\n",
    "        - only the most recent burst matters\n",
    "    - formula can be expanded to include each former burst explicitly\n",
    "        - $\\tau_{n+1} = \\alpha t_n + \\alpha(1 - \\alpha) t_{n-1} + ... + \\alpha(1 - \\alpha)^j t_{n-j} + ...$\n",
    "            - $\\tau_{n+1}$ is the next predicted burst time\n",
    "            - $t_n$ is the actual burst time\n",
    "            - $\\alpha$ is the weight given to the most recent burst\n",
    "            - $j$ is the number of bursts ago\n",
    "    - <img src=\"images/BurstEstEg.png\">\n",
    "        \n",
    "        - blue is estimate\n",
    "        - if actual time is constant, estimate approaches actual time\n",
    "                - .5(20)+.5(20) = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1af6867e152",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preemptive SJF\n",
    "- new shorter processes can preempt longer currently running processes\n",
    "- <img src=\"images/preSJFeg.png\">\n",
    "\n",
    "    1. P1 scheduled at $t_0$\n",
    "    2. P2 arrives and scheduler is activated\n",
    "        - P1 has an expected remaining burst time of 7 units\n",
    "        - P2's expected burst time < 7\n",
    "        - P2 preempts P1\n",
    "    3. P3 arrives and scheduler is activated\n",
    "        - P2 has an expected remaining burst time of 3 units\n",
    "        - P3's expected burst time > 3\n",
    "        - P3 is added to the ready queue\n",
    "    4. P4 arrives and scheduler is activated\n",
    "        - P2 has an expected remaining burst time of 2 units\n",
    "        - P4's expected burst time > 2\n",
    "        - P4 is added to the ready queue\n",
    "    5. P2 completes, 3 processes remain in the ready queue\n",
    "    - flow:\n",
    "        - 0 to 1: P1\n",
    "        - 1 to 5: P2\n",
    "        - 5 to 10: P4\n",
    "        - 10 to 17: P1\n",
    "        - 17 to 26: P3\n",
    "        <img src=\"images/preSJFeg1.png\">\n",
    "        \n",
    "    - W(P1) = 17 - 8 - 0 = 9\n",
    "    - W(P2) = 5 - 4 - 1 = 0\n",
    "    - W(P3) = 26 - 9 - 2 = 15\n",
    "    - W(P4) = 10 - 5 - 3 = 2\n",
    "    - Ave(W) = $\\frac{9 + 0 + 15 + 2}{4} = \\frac{26}{4} = 6.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e4f6d845503ba1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Priority Scheduling\n",
    "- priority number is associated with each process\n",
    "- CPU allocated to the process with highest priority\n",
    "    - ties broken in FCFS order\n",
    "- internally determined priorities\n",
    "    - time limit, memory requirements, etc\n",
    "    - SFJ uses next CPU burst time for priority\n",
    "- externally determined priorities\n",
    "    - process importance, user level, etc\n",
    "- can be preemptive or not\n",
    "- low number generally means higher priority\n",
    "- advantages\n",
    "    - priorities can be as general as needed\n",
    "- disadvantages\n",
    "    - low priority processes may never execute\n",
    "- aging\n",
    "    - technique to prevent starvation\n",
    "    - as time progresses, increase the priority of the process\n",
    "        - no one true method for implementing aging "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899dc7a66fa233f2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Round Robin\n",
    "- algorithm\n",
    "    - arrange jobs in FCFS order\n",
    "    - allocate CPU to first job for one time slice\n",
    "    - preempt job if it does not complete in one time slice and put it at the end of the ready queue\n",
    "        - if it does complete, it cedes the CPU voluntarily\n",
    "    - allocate CPU to next job in FCFS order\n",
    "- a time slice is called a time quantum\n",
    "- by definition preemptive\n",
    "    - can be considered FCFS with preemption\n",
    "- advantages\n",
    "    - simple\n",
    "    - avoids starvation\n",
    "- disadvantages\n",
    "    - may involve a lot of context switching\n",
    "    - higher average wait time than SJF\n",
    "        - SJF is optimal so any other algorithm will have a higher average wait time\n",
    "    - I/O bound processes may suffer on heavily loaded systems\n",
    "        - i.e. it will lose portions of it's time slice to other processes if waiting for I/O\n",
    "- e.g. \n",
    "    <img src=\"images/RoundRobin.png\"> \n",
    "- performance depends on the size of the time quantum\n",
    "    - with long time quantum, it is essentially FCFS\n",
    "    - with short time quantum, it has high context switching overhead\n",
    "- general characteristics\n",
    "    - time quanta are usually 10 to 100 milliseconds\n",
    "    - context switching overhead is usually < 10 microseconds\n",
    "    - results in longer wait times\n",
    "    - better response time in interactive systems\n",
    "        - turnaround time depends on the size of the time quantum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343ac6b7e816470",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lotery Scheduling\n",
    "- built to address the fairness issue of priority scheduling\n",
    "- algorithm\n",
    "    - each process has some tickets\n",
    "    - scheduler draws a random ticket each time slice\n",
    "    - on average, allocated CPU time for a process is proportional to number of tickets held\n",
    "- to approximate SJF, short jobs get more tickets\n",
    "    - SJF is optimal\n",
    "- all jobs get at least one ticket\n",
    "    - to prevent starvation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb54ebe8545712",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Multilevel Queue Scheduling\n",
    "- most OSes have multiple scheduling algorithms\n",
    "- ready queue is partitioned into separate queues\n",
    "    - e.g. foreground (interactive) and background (batch)\n",
    "- each queue has its own scheduling algorithm\n",
    "    - foreground - RR\n",
    "    - background - FCFS\n",
    "- scheduling must be done between the queues\n",
    "    - i.e. the schedulers must be scheduled\n",
    "    - fixed priority scheduling\n",
    "        - i.e. serve all from foreground then from background\n",
    "        - e.g. foreground gets 80% of CPU, background gets 20%\n",
    "    - time slice\n",
    "        - i.e queue gets a certain amount of CPU time which it can schedule amongst it's processes\n",
    "        - e.g. 80% foreground RR, 20% background FCFS\n",
    "- useful when\n",
    "    - processes can be easily classified into groups\n",
    "    - each group has different scheduling needs\n",
    "- algorithm\n",
    "    - partition ready queue into separate queues\n",
    "    - determine some scheduling algorithm for each queue\n",
    "        - e.g. RR, SJF, FCFS, etc\n",
    "    - determine the inter-queue scheduling method\n",
    "        - e.g. fixed priority, time slice, etc\n",
    "    - permanently assign processes to one queue\n",
    "        - e.g. foreground and background\n",
    "- **processes do not move between queues automatically**\n",
    "    - e.g. a process cannot move from foreground to background without user intervention\n",
    "    - e.g. a process cannot move from background to foreground without user intervention\n",
    "- e.g.\n",
    "    <img src=\"images/MultilevelQueue.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e03684857facc7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Multilevel Feedback Queue Scheduling\n",
    "- allows processes to move between queues dynamically\n",
    "- algorithm\n",
    "    - multiple queues with different scheduling algorithms\n",
    "    - round robin scheduling between the queues\n",
    "    - run highest priority jobs first, then lower priority jobs\n",
    "    - jobs start in the highest priority queue\n",
    "    - if time slice expires, move down one queue\n",
    "    - if time slice does not expire, move up one queue\n",
    "- different queues may have a different number of time slices\n",
    "    - e.g. priority 0 may only allow 1 slice, priority 1 may allow 2 slices, etc\n",
    "- approximates SRTF (shortest remaining time first)\n",
    "    - CPU bound processes will move down the queue quickly\n",
    "    - I/O bound processes will move up the queue quickly\n",
    "- unfair for long running processes\n",
    "    - they will always be in the lowest priority queue\n",
    "    - countermeasure: aging\n",
    "        - increase priority of processes that have been waiting for a long time\n",
    "        - difficult to tune aging parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12bfa76b21ff127",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Case Study: Solaris\n",
    "- priority based scheduling\n",
    "    - six classes\n",
    "        - real time, system, interactive, fair share, time share, and idle\n",
    "            - listed in order of priority\n",
    "        - different classes have different scheduling algorithms\n",
    "            - e.g. real time is FCFS, interactive is round robin, etc\n",
    "    - default class is time share\n",
    "        - uses multilevel feedback queue scheduling\n",
    "        - inverse relation between time slice and priority\n",
    "            - higher priority = shorter time slice\n",
    "            - lower priority = longer time slice\n",
    "        - good response time for interactive processes\n",
    "        - good throughput for CPU bound processes\n",
    "- 60 priority levels\n",
    "    - 0 to 59\n",
    "    - 0 is highest priority\n",
    "    - 59 is lowest priority\n",
    "    - 60 is reserved for the idle process\n",
    "- <img src=\"images/solarisdispatch.png\">\n",
    "\n",
    "    - the Solaris dispatch table\n",
    "    - `time quantum` is the time slice\n",
    "    - `time quantum expired` is the queue a process is sent to if the time slice expires\n",
    "    - `return from sleep` is queue a process is sent to if the time slice does not expire\n",
    "- Note for Exams:\n",
    "    - scheduler does not preempt even if round robin unless specified in question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fbe2f87be1d4c5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Thread Scheduling\n",
    "- Linux only supports one to one mapping\n",
    "    - one user thread per kernel thread\n",
    "    - so the below is not applicable to Linux\n",
    "- on systems supporting threads,\n",
    "    - kernel threads are the real scheduling entities\n",
    "    - user threads must be mapped to kernel threads\n",
    "    - scheduling attributes may be set at thread creation\n",
    "- Contention-scope\n",
    "    - PTHREAD_SCOPE_PROCESS\n",
    "        - group user threads to contend for kernel threads\n",
    "        - threads are scheduled together at the process level\n",
    "            - i.e. threads are scheduled together with other threads\n",
    "    - PTHREAD_SCOPE_SYSTEM\n",
    "        - directly assigned to kernel threads, contend with other kernel threads\n",
    "        - threads are scheduled independently at the system level\n",
    "            - i.e. threads are scheduled independently of other threads\n",
    "- inheritsched\n",
    "    - PTHREAD_INHERIT_SCHED\n",
    "        - new threads inherit scheduling attributes of creating thread\n",
    "    - PTHREAD_EXPLICIT_SCHED\n",
    "        - new threads are created with explicitly specified attributes\n",
    "- schedpolicy\n",
    "    - SCHED_OTHER\n",
    "        - default scheduling policy\n",
    "        - regular non-real-time scheduling\n",
    "        - time sharing\n",
    "    - SCHED_FIFO\n",
    "        - real time FCFS\n",
    "        - first in first out\n",
    "    - SCHED_RR\n",
    "        - round robin\n",
    "- schedparam\n",
    "    - set/get priority of the thread\n",
    "- all parameters are only relevant when\n",
    "    - thread library supports many to one user level threads\n",
    "    - real-time scheduling "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- pthread scheduling example\n",
    "```C\n",
    "int main(int argc, char *argv[]){\n",
    "    int i;\n",
    "    pthread_t tid[5];\n",
    "    pthread_attr_t attr;\n",
    "    \n",
    "    pthread_attr_init(&attr); /* get the default attributes */\n",
    "    /* set the scheduling algorithm to PROCESS or SYSTEM */\n",
    "    pthread_attr_setscope(&attr, PTHREAD_SCOPE_SYSTEM);\n",
    "    /* set the scheduling policy - FIFO, RT, or OTHER */\n",
    "    pthread_attr_setschedpolicy(&attr, SCHED_OTHER);\n",
    "    \n",
    "    for (i = 0; i < 5; i++)\n",
    "        pthread_create(&tid[i],&attr,runner,NULL);\n",
    "    for (i = 0; i < NUM_THREADS; i++)\n",
    "        pthread_join(tid[i], NULL);\n",
    "}\n",
    "void *runner(void *param){ \n",
    "    printf(\"I am a thread\\n\");\n",
    "    pthread_exit(0);\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98fb8896c075645b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multiprocessor Scheduling Issues\n",
    "- multiprocessor scheduling\n",
    "    - asymmetric multiprocessing\n",
    "        - only one processor runs the OS and accesses the system data structures\n",
    "        - other processors are slaves\n",
    "        - master processor distributes work to slaves\n",
    "        - master may become a bottleneck\n",
    "    - symmetric multiprocessing (more common)\n",
    "        - each processor runs the OS and accesses the system data structures\n",
    "        - each processor is self scheduling\n",
    "        - each processor may have it's own private ready queue\n",
    "        - processors may share a common ready queue\n",
    "            - this is more common\n",
    "        - advantage\n",
    "            - no race conditions\n",
    "            - load balancing\n",
    "                - distribute processes evenly across processors\n",
    "        - disadvantage\n",
    "            - more complex\n",
    "            - more overhead\n",
    "- process affinity\n",
    "    - process has affinity for the processor it is currently running on\n",
    "    - reduces memory and cache overhead\n",
    "        - caches on a given processor will already have the data for the process running on that processor\n",
    "        - moving the process to another processor will cause the caches to be flushed and refilled\n",
    "    - memory affinity is important for NUMA systems\n",
    "        - non-uniform memory access\n",
    "        - memory access time depends on the location of the memory relative to the processor\n",
    "    - soft and hard processor affinity\n",
    "        - how strictly the OS follows the affinity\n",
    "        - soft affinity\n",
    "            - process prefers to run on a particular processor\n",
    "            - but can be moved to another processor\n",
    "        - hard affinity\n",
    "            - process can only run on a particular processor\n",
    "            - cannot be moved to another processor\n",
    "- load balancing\n",
    "    - evenly distribute processes across processors\n",
    "    - important if each processor has it's own ready queue\n",
    "    - uses *push migration* and *pull migration*\n",
    "        - push/pull processes from busy processors to idle processors\n",
    "        - push migration\n",
    "            - periodically check the load on each processor\n",
    "            - if a processor is overloaded, move a process to another processor\n",
    "        - pull migration\n",
    "            - idle processors pull processes from busy processors\n",
    "            - idle processors periodically check the load on busy processors\n",
    "            - if a processor is overloaded, pull a process from it\n",
    "- multicore processors\n",
    "    - multiple processors on a single chip\n",
    "        - uniform memory access\n",
    "        - faster intercore communication\n",
    "    - may be simultaneously multithreaded (SMT)\n",
    "        - each core can execute multiple threads simultaneously\n",
    "        - instructions from multiple threads are simultaneously live in different pipeline stages\n",
    "        - OS is given a view of one processor per hardware thread\n",
    "        - may reduce memory stalls\n",
    "        - may increase resource contention\n",
    "        - e.g. Intel Hyperthreading\n",
    "- "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a62379f7b4612259"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
